# lime_explanation.py
# 安装依赖
!pip install -q numpy==1.23.5 tensorflow==2.14.1 alibi==0.9.6 lime==0.2.0.1

import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing import sequence
from alibi.explainers import IntegratedGradients
import lime.lime_text

# 配置参数
max_features = 5000  # 减小词汇量
maxlen = 50          # 缩短序列长度

# 加载精简数据集
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)
x_train = sequence.pad_sequences(x_train, maxlen=maxlen)
x_test = sequence.pad_sequences(x_test, maxlen=maxlen)

# 构建简化模型
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(max_features, 32),
    tf.keras.layers.GlobalAvgPool1D(),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(x_train, y_train, epochs=2, batch_size=128)  # 快速训练

# LIME解释主程序
def lime_explain(sentence):
    # 文本预处理管道
    word_index = imdb.get_word_index()
    reverse_index = {v+3: k for k, v in word_index.items()}
    
    def text_to_seq(text):
        return [word_index.get(word.lower(), 0)+3 for word in text.split()][:maxlen]
    
    # 初始化解释器
    explainer = lime.lime_text.LimeTextExplainer(class_names=["neg", "pos"])
    
    # 预测函数
    def predict_fn(texts):
        seqs = [text_to_seq(txt) for txt in texts]
        padded = sequence.pad_sequences(seqs, maxlen=maxlen)
        return model.predict(padded)
    
    # 生成解释
    exp = explainer.explain_instance(sentence, predict_fn, num_features=8)
    exp.show_in_notebook()

# 测试案例
if __name__ == "__main__":
    test_sentence = (
        "A powerful study of loneliness sexual and desperation. Be patient throughout the atmosphere "
        "and pay attention to the wonderfully written script."
    )
    lime_explain(test_sentence)
